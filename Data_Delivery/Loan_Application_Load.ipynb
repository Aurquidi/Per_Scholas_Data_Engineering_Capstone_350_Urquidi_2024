{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d3b5fa67-8a53-48a2-8e2e-0f8c7fe6972d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mysql-connector-python in c:\\users\\chito\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (9.0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.1.1 -> 24.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\chito\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\chito\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\chito\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\chito\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\chito\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests) (2024.2.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.1.1 -> 24.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mysql-connector-python in c:\\users\\chito\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (9.0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.1.1 -> 24.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: cryptography in c:\\users\\chito\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (42.0.8)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\chito\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from cryptography) (1.16.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\chito\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from cffi>=1.12->cryptography) (2.22)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.1.1 -> 24.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install mysql-connector-python\n",
    "!pip install requests\n",
    "!pip install --upgrade mysql-connector-python\n",
    "!pip install cryptography"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4f13bfb4-c41e-455e-b6b3-b104402e53c8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import pyspark.sql.functions as funct\n",
    "from pyspark.sql.types import *\n",
    "import mysql.connector as msql\n",
    "from mysql.connector import Error\n",
    "import pandas as pd\n",
    "import cryptography\n",
    "import credentials as cred\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6ffe572a-22d0-479a-9928-2ab7a1d824d2",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# **Data Extraction from the Loan Data _API_**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cb2eaa83-f27c-451b-8ee8-b26947735d53",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "###  Extracting the data from the API endpoint and storing it in a Spark dataframe.  The API url is provided in the Capstone Guidance Document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3e3083ed-dfe0-4aca-a6b9-d51bc93e11ec",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status code: 200\n",
      "{'Connection': 'keep-alive', 'Content-Length': '3943', 'Cache-Control': 'max-age=300', 'Content-Security-Policy': \"default-src 'none'; style-src 'unsafe-inline'; sandbox\", 'Content-Type': 'text/plain; charset=utf-8', 'ETag': 'W/\"a8013af2b71077e4636d6d2d52ae3431aa0fae0b32dc61b867578cf1100b198b\"', 'Strict-Transport-Security': 'max-age=31536000', 'X-Content-Type-Options': 'nosniff', 'X-Frame-Options': 'deny', 'X-XSS-Protection': '1; mode=block', 'X-GitHub-Request-Id': 'E388:1492DA:3CB737:414A39:668C9E91', 'Content-Encoding': 'gzip', 'Accept-Ranges': 'bytes', 'Date': 'Tue, 09 Jul 2024 02:24:12 GMT', 'Via': '1.1 varnish', 'X-Served-By': 'cache-chi-kigq8000037-CHI', 'X-Cache': 'HIT', 'X-Cache-Hits': '0', 'X-Timer': 'S1720491852.021088,VS0,VE1', 'Vary': 'Authorization,Accept-Encoding,Origin', 'Access-Control-Allow-Origin': '*', 'Cross-Origin-Resource-Policy': 'cross-origin', 'X-Fastly-Request-ID': '8fdad8a735cdd3db04acbec3f887c2d0b31917aa', 'Expires': 'Tue, 09 Jul 2024 02:29:12 GMT', 'Source-Age': '184'}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/platformps/LoanDataset/main/loan_data.json'\n",
    "\n",
    "\n",
    "\n",
    "response = requests.get(url)\n",
    "response.headers[\"Content-Type\"]\n",
    "api_results = response.json()\n",
    "print(f\"Status code: {response.status_code}\")\n",
    "print(f\"{response.headers}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a spark dataframe, loan_application_df, from the API response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------------------+--------------+----------+------------+------+------+-------+-------------+-------------+\n",
      "|Application_ID|Application_Status|Credit_History|Dependents|   Education|Gender|Income|Married|Property_Area|Self_Employed|\n",
      "+--------------+------------------+--------------+----------+------------+------+------+-------+-------------+-------------+\n",
      "|      LP001002|                 Y|             1|         0|    Graduate|  Male|medium|     No|        Urban|           No|\n",
      "|      LP001003|                 N|             1|         1|    Graduate|  Male|medium|    Yes|        Rural|           No|\n",
      "|      LP001005|                 Y|             1|         0|    Graduate|  Male|   low|    Yes|        Urban|          Yes|\n",
      "|      LP001006|                 Y|             1|         0|Not Graduate|  Male|   low|    Yes|        Urban|           No|\n",
      "|      LP001008|                 Y|             1|         0|    Graduate|  Male|medium|     No|        Urban|           No|\n",
      "+--------------+------------------+--------------+----------+------------+------+------+-------+-------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create Spark DataFrame\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder.appName(\"LoanApplication\").getOrCreate()\n",
    "\n",
    "# Create DataFrame from API results\n",
    "loan_application_df = spark.createDataFrame(api_results)\n",
    "\n",
    "# Show the first few rows of the DataFrame\n",
    "loan_application_df.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Application_ID: string (nullable = true)\n",
      " |-- Application_Status: string (nullable = true)\n",
      " |-- Credit_History: long (nullable = true)\n",
      " |-- Dependents: string (nullable = true)\n",
      " |-- Education: string (nullable = true)\n",
      " |-- Gender: string (nullable = true)\n",
      " |-- Income: string (nullable = true)\n",
      " |-- Married: string (nullable = true)\n",
      " |-- Property_Area: string (nullable = true)\n",
      " |-- Self_Employed: string (nullable = true)\n",
      "\n",
      "+--------------+------------------+--------------+----------+------------+------+------+-------+-------------+-------------+\n",
      "|Application_ID|Application_Status|Credit_History|Dependents|   Education|Gender|Income|Married|Property_Area|Self_Employed|\n",
      "+--------------+------------------+--------------+----------+------------+------+------+-------+-------------+-------------+\n",
      "|      LP001002|                 Y|             1|         0|    Graduate|  Male|medium|     No|        Urban|           No|\n",
      "|      LP001003|                 N|             1|         1|    Graduate|  Male|medium|    Yes|        Rural|           No|\n",
      "|      LP001005|                 Y|             1|         0|    Graduate|  Male|   low|    Yes|        Urban|          Yes|\n",
      "|      LP001006|                 Y|             1|         0|Not Graduate|  Male|   low|    Yes|        Urban|           No|\n",
      "|      LP001008|                 Y|             1|         0|    Graduate|  Male|medium|     No|        Urban|           No|\n",
      "|      LP001011|                 Y|             1|         2|    Graduate|  Male|medium|    Yes|        Urban|          Yes|\n",
      "|      LP001013|                 Y|             1|         0|Not Graduate|  Male|   low|    Yes|        Urban|           No|\n",
      "|      LP001014|                 N|             0|        3+|    Graduate|  Male|   low|    Yes|    Semiurban|           No|\n",
      "|      LP001018|                 Y|             1|         2|    Graduate|  Male|medium|    Yes|        Urban|           No|\n",
      "|      LP001020|                 N|             1|         1|    Graduate|  Male|  high|    Yes|    Semiurban|           No|\n",
      "|      LP001024|                 Y|             1|         2|    Graduate|  Male|   low|    Yes|        Urban|           No|\n",
      "|      LP001028|                 Y|             1|         2|    Graduate|  Male|   low|    Yes|        Urban|           No|\n",
      "|      LP001029|                 N|             1|         0|    Graduate|  Male|   low|     No|        Rural|           No|\n",
      "|      LP001030|                 Y|             1|         2|    Graduate|  Male|   low|    Yes|        Urban|           No|\n",
      "|      LP001032|                 Y|             1|         0|    Graduate|  Male|medium|     No|        Urban|           No|\n",
      "+--------------+------------------+--------------+----------+------------+------+------+-------+-------------+-------------+\n",
      "only showing top 15 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Reviewing the schema along with the Data that has been loaded\n",
    "loan_application_df.printSchema()\n",
    "loan_application_df.show(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the schema described above to create a Spark dataframe that will maintain the structure types, structure fields, string and long types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------------------+--------------+----------+------------+------+------+-------+-------------+-------------+\n",
      "|Application_ID|Application_Status|Credit_History|Dependents|   Education|Gender|Income|Married|Property_Area|Self_Employed|\n",
      "+--------------+------------------+--------------+----------+------------+------+------+-------+-------------+-------------+\n",
      "|      LP001002|                 Y|             1|         0|    Graduate|  Male|medium|     No|        Urban|           No|\n",
      "|      LP001003|                 N|             1|         1|    Graduate|  Male|medium|    Yes|        Rural|           No|\n",
      "|      LP001005|                 Y|             1|         0|    Graduate|  Male|   low|    Yes|        Urban|          Yes|\n",
      "|      LP001006|                 Y|             1|         0|Not Graduate|  Male|   low|    Yes|        Urban|           No|\n",
      "|      LP001008|                 Y|             1|         0|    Graduate|  Male|medium|     No|        Urban|           No|\n",
      "+--------------+------------------+--------------+----------+------------+------+------+-------+-------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+-------+--------------+------------------+------------------+------------------+------------+------+------+-------+-------------+-------------+\n",
      "|summary|Application_ID|Application_Status|    Credit_History|        Dependents|   Education|Gender|Income|Married|Property_Area|Self_Employed|\n",
      "+-------+--------------+------------------+------------------+------------------+------------+------+------+-------+-------------+-------------+\n",
      "|  count|           511|               511|               511|               511|         511|   511|   511|    511|          511|          511|\n",
      "|   mean|          NULL|              NULL|0.8434442270058709|0.5588865096359743|        NULL|  NULL|  NULL|   NULL|         NULL|         NULL|\n",
      "| stddev|          NULL|              NULL|0.3637375108305915|0.7904073771519633|        NULL|  NULL|  NULL|   NULL|         NULL|         NULL|\n",
      "|    min|      LP001002|                 N|                 0|                 0|    Graduate|Female|  high|     No|        Rural|           No|\n",
      "|    max|      LP002990|                 Y|                 1|                3+|Not Graduate|  Male|medium|    Yes|        Urban|          Yes|\n",
      "+-------+--------------+------------------+------------------+------------------+------------+------+------+-------+-------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create Spark DataFrame with the specified schema\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, LongType\n",
    "\n",
    "# Define the schema\n",
    "schema = StructType([\n",
    "    StructField(\"Application_ID\", StringType(), True),\n",
    "    StructField(\"Application_Status\", StringType(), True),\n",
    "    StructField(\"Credit_History\", LongType(), True),\n",
    "    StructField(\"Dependents\", StringType(), True),\n",
    "    StructField(\"Education\", StringType(), True),\n",
    "    StructField(\"Gender\", StringType(), True),\n",
    "    StructField(\"Income\", StringType(), True),\n",
    "    StructField(\"Married\", StringType(), True),\n",
    "    StructField(\"Property_Area\", StringType(), True),\n",
    "    StructField(\"Self_Employed\", StringType(), True)\n",
    "])\n",
    "\n",
    "\n",
    "# Create DataFrame from API results with the specified schema\n",
    "loan_application_df = spark.createDataFrame(api_results, schema)\n",
    "\n",
    "# Show the first few rows of the DataFrame\n",
    "loan_application_df.show(5)\n",
    "loan_application_df.describe().show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Establishing DB connection to create the CDW_SAPP_loan_application table as per the guidance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table created successfully\n",
      "MySQL connection is closed\n"
     ]
    }
   ],
   "source": [
    "# Prepare for MySQL connection\n",
    "host = cred.host\n",
    "user = cred.user\n",
    "password = cred.password\n",
    "database = \"creditcard_capstone\"\n",
    "\n",
    "# Connect to MySQL and create table\n",
    "try:\n",
    "    conn = msql.connect(host=host, user=user, password=password, database=database)\n",
    "    if conn.is_connected():\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        # Create table with the specified schema\n",
    "        create_table_query = \"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS CDW_SAPP_loan_application (\n",
    "            Application_ID VARCHAR(255),\n",
    "            Application_Status VARCHAR(255),\n",
    "            Credit_History BIGINT,\n",
    "            Dependents VARCHAR(255),\n",
    "            Education VARCHAR(255),\n",
    "            Gender VARCHAR(255),\n",
    "            Income VARCHAR(255),\n",
    "            Married VARCHAR(255),\n",
    "            Property_Area VARCHAR(255),\n",
    "            Self_Employed VARCHAR(255)\n",
    "        )\n",
    "        \"\"\"\n",
    "        cursor.execute(create_table_query)\n",
    "        print(\"Table created successfully\")\n",
    "\n",
    "except Error as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    print(f\"Error type: {type(e).__name__}\")\n",
    "    print(f\"Error args: {e.args}\")\n",
    "\n",
    "finally:\n",
    "    if 'conn' in locals() and conn.is_connected():\n",
    "        cursor.close()\n",
    "        conn.close()\n",
    "        print(\"MySQL connection is closed\")\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This next step will write the spark dataframe, loan_application_df to the MYSQL creditcard_capstone.CDW_SAPP_loan_application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_application_df.write.format(\"jdbc\") \\\n",
    "  .mode(\"append\") \\\n",
    "  .option(\"url\", \"jdbc:mysql://localhost:3306/creditcard_capstone\") \\\n",
    "  .option(\"dbtable\", \"creditcard_capstone.CDW_SAPP_loan_application\") \\\n",
    "  .option(\"user\", cred.user) \\\n",
    "  .option(\"password\", cred.password) \\\n",
    "  .save()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3e2a24d9-3c0c-46a4-9737-5f6230166f8c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Converting quickly to pandas_df to see appearance of data and appearance of table columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "05ac08af-2de3-4205-96bc-fbd13be3f244",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Application_ID</th>\n",
       "      <th>Application_Status</th>\n",
       "      <th>Credit_History</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>Education</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Income</th>\n",
       "      <th>Married</th>\n",
       "      <th>Property_Area</th>\n",
       "      <th>Self_Employed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LP001002</td>\n",
       "      <td>Y</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Male</td>\n",
       "      <td>medium</td>\n",
       "      <td>No</td>\n",
       "      <td>Urban</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LP001003</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Male</td>\n",
       "      <td>medium</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Rural</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LP001005</td>\n",
       "      <td>Y</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Male</td>\n",
       "      <td>low</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LP001006</td>\n",
       "      <td>Y</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Not Graduate</td>\n",
       "      <td>Male</td>\n",
       "      <td>low</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Urban</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LP001008</td>\n",
       "      <td>Y</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Male</td>\n",
       "      <td>medium</td>\n",
       "      <td>No</td>\n",
       "      <td>Urban</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Application_ID Application_Status  Credit_History Dependents     Education  \\\n",
       "0       LP001002                  Y               1          0      Graduate   \n",
       "1       LP001003                  N               1          1      Graduate   \n",
       "2       LP001005                  Y               1          0      Graduate   \n",
       "3       LP001006                  Y               1          0  Not Graduate   \n",
       "4       LP001008                  Y               1          0      Graduate   \n",
       "\n",
       "  Gender  Income Married Property_Area Self_Employed  \n",
       "0   Male  medium      No         Urban            No  \n",
       "1   Male  medium     Yes         Rural            No  \n",
       "2   Male     low     Yes         Urban           Yes  \n",
       "3   Male     low     Yes         Urban            No  \n",
       "4   Male  medium      No         Urban            No  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas_df = loan_application_df.toPandas()\n",
    "pandas_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                   Version\n",
      "------------------------- -----------\n",
      "asttokens                 2.4.1\n",
      "attrs                     23.2.0\n",
      "blinker                   1.8.2\n",
      "certifi                   2024.2.2\n",
      "cffi                      1.16.0\n",
      "charset-normalizer        3.3.2\n",
      "click                     8.1.7\n",
      "colorama                  0.4.6\n",
      "comm                      0.2.2\n",
      "contourpy                 1.2.1\n",
      "cryptography              42.0.8\n",
      "cycler                    0.12.1\n",
      "dash                      2.17.0\n",
      "dash-core-components      2.0.0\n",
      "dash-html-components      2.0.0\n",
      "dash-table                5.0.0\n",
      "debugpy                   1.8.1\n",
      "decorator                 5.1.1\n",
      "executing                 2.0.1\n",
      "fastjsonschema            2.19.1\n",
      "findspark                 2.0.1\n",
      "Flask                     3.0.3\n",
      "fonttools                 4.51.0\n",
      "grpcio                    1.64.1\n",
      "grpcio-tools              1.64.1\n",
      "idna                      3.7\n",
      "importlib_metadata        7.1.0\n",
      "ipykernel                 6.29.4\n",
      "ipython                   8.23.0\n",
      "itsdangerous              2.2.0\n",
      "jedi                      0.19.1\n",
      "Jinja2                    3.1.4\n",
      "joblib                    1.4.2\n",
      "jsonschema                4.22.0\n",
      "jsonschema-specifications 2023.12.1\n",
      "jupyter_client            8.6.1\n",
      "jupyter_core              5.7.2\n",
      "kiwisolver                1.4.5\n",
      "MarkupSafe                2.1.5\n",
      "matplotlib                3.9.0\n",
      "matplotlib-inline         0.1.7\n",
      "more-itertools            10.2.0\n",
      "mysql-connector           2.2.9\n",
      "mysql-connector-python    9.0.0\n",
      "nbformat                  5.10.4\n",
      "nest-asyncio              1.6.0\n",
      "numpy                     1.26.4\n",
      "packaging                 24.0\n",
      "pandas                    2.2.2\n",
      "parso                     0.8.4\n",
      "pillow                    10.3.0\n",
      "pip                       24.1.1\n",
      "platformdirs              4.2.1\n",
      "plotly                    5.22.0\n",
      "prompt-toolkit            3.0.43\n",
      "protobuf                  5.27.2\n",
      "psutil                    5.9.8\n",
      "pure-eval                 0.2.2\n",
      "py4j                      0.10.9.7\n",
      "pyarrow                   16.1.0\n",
      "pycparser                 2.22\n",
      "Pygments                  2.17.2\n",
      "PyMySQL                   1.1.1\n",
      "pyparsing                 3.1.2\n",
      "pyspark                   3.5.1\n",
      "python-dateutil           2.9.0.post0\n",
      "pytz                      2024.1\n",
      "pywin32                   306\n",
      "pyzmq                     26.0.2\n",
      "referencing               0.35.1\n",
      "requests                  2.31.0\n",
      "retrying                  1.3.4\n",
      "rpds-py                   0.18.1\n",
      "scikit-learn              1.5.0\n",
      "scipy                     1.13.1\n",
      "seaborn                   0.13.2\n",
      "setuptools                65.5.0\n",
      "six                       1.16.0\n",
      "stack-data                0.6.3\n",
      "tenacity                  8.3.0\n",
      "threadpoolctl             3.5.0\n",
      "tornado                   6.4\n",
      "traitlets                 5.14.3\n",
      "typing_extensions         4.11.0\n",
      "tzdata                    2024.1\n",
      "urllib3                   2.2.1\n",
      "wcwidth                   0.2.13\n",
      "Werkzeug                  3.0.3\n",
      "zipp                      3.19.1\n"
     ]
    }
   ],
   "source": [
    "!pip list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f21f6173-1750-4315-b32a-468f863f101d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Loan_Application 2024-07-05 14:20:28",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
